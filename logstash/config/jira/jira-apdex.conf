input {
    file {
        path => "/usr/share/logstash/logs/**/atlassian-jira-apdex.log*"
        mode => "read"
        file_completed_action => "log"
        file_completed_log_path => "/tmp/atlassian-jira-apdex_fileinput.log"
        sincedb_path => "/tmp/atlassian-jira-apdex_dbfile"
    }
}


filter {
    grok {
        match => { "message" => [
                           '(?m)%{TIMESTAMP_ISO8601:timestamp} category\: %{NOTSPACE:catagory} apdex\: \{apdexScore=%{INT:apdexScore}, satisfiedCount=%{INT:satisfiedCount}, toleratingCount=%{INT:toleratingCount}, frustratedCount=%{INT:frustratedCount}\}',
                           "(?m)%{TIMESTAMP_ISO8601:timestamp} %{GREEDYDATA:messagepart}"
                   ]
        }
    }

    grok {
        match => { "path" => "%{UNIXPATH:subpath}" }
    }
    mutate {
        split => { "subpath" => "/" }
    }

    ruby {
        code => "event.set('node',event.get('subpath')[6]); event.set('supportzip', event.get('subpath').length > 2 ? event.get('subpath')[7]:'none')"
    }


        # parse date time. match element lists possible patterns
        date {
            match => [ "timestamp" , "ISO8601"]
            target => "@timestamp"
        }
        # if we can't parse the date let's add it as a tag to later check

        mutate {
            convert => [ "apdexScore", "integer" ]
        }
        mutate {
            convert => [ "satisfiedCount", "integer" ]
        }
        mutate {
            convert => [ "toleratingCount", "integer" ]
        }
        mutate {
            convert => [ "frustratedCount", "integer" ]
        }
        # remove temporary fields
        mutate {
            remove_field => ["subpath", "message"]
        }
    }

output {
    stdout { codec => rubydebug}
    elasticsearch {
        hosts => "elasticsearch:9200"
        # set to single index output as this data can span across many many days
        index => "atlassian-jira-apdex"
    }
}